
# LiteLLM
#
# LiteLLM is a proxy for LLM providers.
#
# See:
# - https://github.com/BerriAI/litellm
# - https://docs.litellm.ai/

# LiteLLM requires a postgres database and prometheus.
# include:
#   - docker-compose.supabase.yml
#   # Prometheus is only available with LiteLLM Enterprise license
#   # - docker-compose.prometheus.yml

services:
  litellm:
    # extends:
    #   file: ../.repos/litellm/docker-compose.yml
    #   service: litellm
    container_name: litellm
    image: ghcr.io/berriai/litellm:main-stable
    volumes:
     - ./config.litellm.yaml:/app/config.yaml
    command:
     - "--config=/app/config.yaml"
     - "--debug"
    ports:
      - "4444:4000"
    environment:
        DATABASE_URL: "postgresql://${LITELLM_POSTGRES_USER}:${LITELLM_POSTGRES_PASSWORD}@db:5432/${LITELLM_POSTGRES_DB}?schema=${LITELLM_POSTGRES_SCHEMA}"
        STORE_MODEL_IN_DB: "True" # allows adding models to proxy via UI
        MASTER_KEY: ${LITELLM_MASTER_KEY} # Key used by services to access litellm proxy
        OPENAI_API_KEY: ${LITELLM_OPENAI_API_KEY}
        ANTHROPIC_API_KEY: ${LITELLM_ANTHROPIC_API_KEY}
        GROQ_API_KEY: ${LITELLM_GROQ_API_KEY}

    # Load local .env file
    # env_file:
    #   - .env

